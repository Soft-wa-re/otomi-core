{{- $v := .Values }}
{{- $vl := $v.apps.velero }}
{{- $pc := $vl | get "cloud" dict }}
{{- $ps := $vl | get "storage" dict }}

resources:
  {{- with $v | get "resources" nil }}
    {{- toYaml . | nindent 2 }}
  {{- else }}
  requests:
    cpu: 500m
    memory: 128Mi
  limits:
    cpu: 1000m
    memory: 512Mi
  {{- end }}

initContainers:
  - name: velero-plugin-for-azure
    image: velero/velero-plugin-for-microsoft-azure:v1.5.0
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 50m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 32Mi
    volumeMounts:
      - mountPath: /target
        name: plugins
  - name: velero-plugin-for-aws
    image: velero/velero-plugin-for-aws:v1.4.0
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 50m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 32Mi
    volumeMounts:
      - mountPath: /target
        name: plugins

podSecurityContext:
  runAsUser: 1000

serviceMonitor:
    enabled: true
    namespace: velero

logLevel: {{ $vl.logLevel }}

configuration:
  {{- with $ps | get "azureBlob" nil }}
  provider: azure
  backupStorageLocation:
    name: otomi
    default: true
    bucket: {{ .bucket }}
    config:
      storageAccount: {{ .storageAccount }}
      resourceGroup: {{ .resourceGroup }}
  {{- end }}
  {{- with $ps | get "s3" nil }}
  provider: aws
  backupStorageLocation:
    name: otomi
    default: true
    bucket: {{ .bucket }}
    config:
      s3Url: {{ .s3Url }}
      region: {{ .region }}
  {{- end }}
  {{- with $ps | get "minioLocal" nil }}
  provider: aws
  backupStorageLocation:
    name: otomi
    default: true
    bucket: velero   
    config:
      s3Url: http://minio.minio.svc.cluster.local:9000
      publicUrl: http://minio.minio.svc.cluster.local:9000
      region: minio
      s3ForcePathStyle: true
  {{- end }}

  {{- with $pc| get "azure" nil }}
  volumeSnapshotLocation:
    name: otomi
    config:
      resourceGroup: {{ .resourceGroup }}
  {{- end }}
  
  {{- with $pc | get "aws" nil }}
  volumeSnapshotLocation:
    name: otomi
    config:
      region: {{ .region }}
  {{- end }}
  
  # defaultVolumesToRestic - 
  # if set Velero will back up all pod volumes using Restic with the exception of: 
  # service account tokens, secrets, config maps and hostpath volumes
  defaultVolumesToRestic: true

credentials:
  secretContents:
    cloud: |
      {{- with $ps | get "azureBlob" nil }}
      AZURE_SUBSCRIPTION_ID={{ .subscriptionId }}
      AZURE_TENANT_ID={{ .tenantId }}
      AZURE_CLIENT_ID={{ .aadClientId }}
      AZURE_CLIENT_SECRET={{ .aadClientSecret }}
      {{- end }}
      {{- with $pc | get "azure" nil }}
      AZURE_RESOURCE_GROUP={{ .resourceGroup }}
      AZURE_CLOUD_NAME={{ .environment }}
      {{- end }}
      {{- with $ps | get "s3" nil }}
      [default]
      aws_access_key_id={{ .accessKeyId }}
      aws_secret_access_key={{ .secretAccessKey }}
      {{- end }}
      {{- with $ps | get "minioLocal" nil }}
      [default]
      aws_access_key_id=otomi-admin
      aws_secret_access_key={{ $v.otomi.adminPassword }}
      {{- end }}

kubectl:
  resources:
    requests:
      cpu: 50m
      memory: 32Mi
    limits:
      cpu: 100m
      memory: 32Mi
  labels: 
    # do not inject sidecar, so the kubectl k8s job can exit container and return the completed status
    sidecar.istio.io/inject: "false"

deployRestic: true

metrics:
  serviceMonitor:
    enabled: true

{{- if or $v.backup.platformSchedule.enabled $v.backup.teamSchedule.enabled }}
schedules:
  {{- if $v.backup.platformSchedule.enabled }}
  gitea:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - gitea
  keycloak:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - keycloak
  drone:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - drone
  {{- if $v.apps.harbor.enabled }}
  harbor:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - harbor
  {{- end }}
  {{- if $v.apps.vault.enabled }}
  vault:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - vault
  {{- end }}
  {{- if $v.apps.argocd.enabled }}
  argocd:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - argocd
  {{- end }}
  {{- if $v.apps.kubeapps.enabled }}
  kubeapps:
    disabled: false
    schedule: {{ $v.backup.platformSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.platformSchedule.ttl }}
      includedNamespaces:
      - kubeapps
  {{- end }}
  {{- end }}
  {{- if $v.backup.teamSchedule.enabled }}
  {{- range $teamId := keys $v.teamConfig }}
  team-{{$teamId}}:
    disabled: false
    schedule: {{ $v.backup.teamSchedule.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.teamSchedule.ttl }}
      includedNamespaces:
      - team-{{$teamId}}
  {{- end }}
  {{- end }}
{{- end }}